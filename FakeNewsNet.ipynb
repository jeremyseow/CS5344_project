{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637d17b1",
   "metadata": {},
   "source": [
    "## FakeNewsNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af22c9b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports\n",
    "import os.path\n",
    "import urllib.request\n",
    "import shutil\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "# external library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# project imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56b3e7",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_download_dataset():\n",
    "    path = \"./dataset/tweets\"\n",
    "    if not os.path.exists(\"./dataset\"):\n",
    "        print(\"downloading tweets...\")\n",
    "        os.mkdir(\"./dataset\")\n",
    "        url = \"https://nusu-my.sharepoint.com/:u:/g/personal/e0809358_u_nus_edu/ETPkp1-0GbBHgB__wyeCS_QBE7_SFluzSCtocU0mUr3Jng\"\n",
    "        with urllib.request.urlopen(url) as response, open(path, 'wb') as out_file:\n",
    "            shutil.copyfileobj(response, out_file)\n",
    "            with zipfile.ZipFile(path + \"/results.zip\", \"r\") as zip_ref:\n",
    "                zip_ref.extractall(path)\n",
    "    return path\n",
    "\n",
    "def to_dataframe(path, truncate_length = 10000):\n",
    "    directories = os.listdir(path)\n",
    "    json_all = []\n",
    "    df_all = pd.DataFrame\n",
    "    print(\"reading first \" + str(truncate_length) + \" json files in \" + str(len(directories)) + \" directories...\")\n",
    "    for index,directory in enumerate(directories):\n",
    "        path_prefix = path + \"/\" + directory + \"/tweets\"\n",
    "        files = os.listdir(path_prefix)\n",
    "        # print(\"reading \" + str(len(files)) + \" json files from directory \" + directory + \" (\" + str(index) + \" of \" + str(len(directories)) + \")\")\n",
    "        json_current = []\n",
    "        for file in files:\n",
    "            path_full = path_prefix + \"/\" + file\n",
    "            with open(path_full, 'r') as json_file:\n",
    "                json_current.append(json.loads(json_file.read()))\n",
    "        df_current = pd.json_normalize(json_current)\n",
    "        assert len(files) == len(json_current)\n",
    "        assert len(files) == df_current.shape[0]\n",
    "        json_all.extend(json_current)\n",
    "        if len(json_all) >= truncate_length:\n",
    "            break\n",
    "        # df_all = pd.concat([df_all, df_current], axis=0, join='outer', sort=False)\n",
    "    df_all = pd.json_normalize(json_all[:truncate_length])\n",
    "    return df_all\n",
    "    \n",
    "def print_df(dfs):\n",
    "    for df in dfs:\n",
    "        print(\"==========\")\n",
    "        print(df.shape)\n",
    "        # print(df.info())\n",
    "    print(\"==========\")\n",
    "    \n",
    "!pwd\n",
    "!ls -l\n",
    "path_dataset = get_or_download_dataset()\n",
    "df_fake_1 = to_dataframe(path_dataset + \"/gossipcop\" + \"/fake\")\n",
    "df_real_2 = to_dataframe(path_dataset + \"/gossipcop\" + \"/real\")\n",
    "df_fake_2 = to_dataframe(path_dataset + \"/politifact\" + \"/fake\")\n",
    "df_real_2 = to_dataframe(path_dataset + \"/politifact\" + \"/real\")\n",
    "print_df([df_fake_1, df_real_2, df_fake_2, df_real_2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e92906",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2491bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
